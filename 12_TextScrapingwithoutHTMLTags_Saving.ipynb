{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMHteDlttJFB+A9chZssfH6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ms624atyale/NLP_2025/blob/main/12_TextScrapingwithoutHTMLTags_Saving.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color = 'red'> üêπ üëÄ üêæ **Text/Content/Web Scraping without HTML tags**\n",
        "\n",
        "## **API-based Data Collection**\n",
        "\n",
        "### <font color = 'blue'> **cf., Crawling (a.k.a. HTML Scraping) or Text Mining**"
      ],
      "metadata": {
        "id": "i02GpCyLr0YR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2EZsUyZMs9F",
        "outputId": "cb548d24-d013-4999-a37c-a471221af27e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.10.5)\n"
          ]
        }
      ],
      "source": [
        "pip install requests"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests #Import the requests library to make HTTP requests.\n",
        "\n",
        "def get_wikipedia_page(title):                   #Define a function\n",
        "    URL = \"https://en.wikipedia.org/w/api.php\"  #Set the API(application program interface) endpoint URL: https://en.wikipedia.org/w/api.php.\n",
        "\n",
        "    PARAMS = {                                  #Build PARAMS (query parameters) for the API request:\n",
        "        \"action\": \"query\",                      #ask the API to run a query\n",
        "        \"format\": \"json\",                       #request a JSON response\n",
        "        \"prop\": \"extracts\",                     #ask for the page extract (clean text summary)\n",
        "        \"titles\": title,                        #specify which page to fetch (by title)\n",
        "        \"explaintext\": 1                        #return plain text (no HTML/markup)\n",
        "\n",
        "    }\n",
        "\n",
        "    headers = {\n",
        "        \"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 \" #header to mimic a normal browser request (helps avoid blocks)\n",
        "                      \"(KHTML, like Gecko) Chrome/123.0 Safari/537.36\"\n",
        "    }\n",
        "\n",
        "    response = requests.get(URL, params=PARAMS, headers=headers)           #Send a GET request to the API with requests\n",
        "\n",
        "    if response.status_code != 200:                                        #Check the HTTP status code: If not 200 OK, print an error message and return None.\n",
        "        print(\"HTTP error:\", response.status_code)\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        data = response.json()                                            #Try to parse the response body as JSON with response.json():\n",
        "    except:\n",
        "        print(\"JSON decode error\")                                        #If JSON decoding fails, print a debug message showing the start of the raw response and return None.\n",
        "        print(\"Raw response:\", response.text[:500])\n",
        "        return None\n",
        "\n",
        "    pages = data.get(\"query\", {}).get(\"pages\", {})                      #Navigate the JSON structure to the page data: data[\"query\"][\"pages\"] (a dictionary keyed by numeric page id).\n",
        "    page = next(iter(pages.values()))                                   #Extract the single page object with next(iter(pages.values())) (handles the unknown page id).\n",
        "    return page.get(\"extract\", \"\")                                      #Return the page‚Äôs plain-text extract via page.get(\"extract\", \"\").\n",
        "                                                                        #If the page exists, this is the article text; if not, it returns an empty string (or None earlier if errors occurred)."
      ],
      "metadata": {
        "id": "jjnTjtQJTa4Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = get_wikipedia_page(\"KPop Demon Hunters\")\n",
        "print(text[:500])                                 #Forward indexing (index 1 to index 499: 500 characters including symbols and white space)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qoldme_2TCV9",
        "outputId": "8b4783eb-3b0d-47ba-8ae9-3c603a3b9e3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KPop Demon Hunters is a 2025 American animated musical urban fantasy film directed by Maggie Kang and Chris Appelhans from a screenplay they co-wrote with Danya Jimenez and Hannah McMechan, based on a story conceived by Kang. Produced by Sony Pictures Animation for Netflix, the film stars the voices of Arden Cho, Ahn Hyo-seop, May Hong, Ji-young Yoo, Yunjin Kim, Daniel Dae Kim, Ken Jeong, and Lee Byung-hun. The film follows a K-pop girl group, Huntr/x, who lead double lives as demon hunters; the\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "titles = [\n",
        "    \"K-pop\",\n",
        "    \"Korean Wave\",\n",
        "    \"KPop Demon Hunters\",\n",
        "    \"Hybe\",\n",
        "    \"BTS\",\n",
        "    \"2024 Nobel Prize in Literature\",\n",
        "    \"Han Kang\",\n",
        "    \"Bong Joon Ho\",\n",
        "    \"Pachinko\",\n",
        "    \"Minjung Son\"\n",
        "]\n",
        "\n",
        "corpus = {}\n",
        "\n",
        "for t in titles:\n",
        "    txt = get_wikipedia_page(t)\n",
        "    if txt:\n",
        "        corpus[t] = txt\n",
        "    else:\n",
        "        print(\"Failed:\", t)\n",
        "\n",
        "# Show first 200 chars for each\n",
        "for title, text in corpus.items():\n",
        "    print(\"\\n====\", title, \"====\")\n",
        "    print(text[:200])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIvw_0cpjOz_",
        "outputId": "40474c0a-361c-4862-cf94-ae5a93bef9b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed: Minjung Son\n",
            "\n",
            "==== K-pop ====\n",
            "K-pop (Korean: ÏºÄÏù¥Ìåù; RR: Keipap; an abbreviation of \"Korean popular music\") is a form of popular music originating in South Korea. The music genre that the term is used to refer to colloquially emerged\n",
            "\n",
            "==== Korean Wave ====\n",
            "The Korean Wave, or hallyu (Korean: ÌïúÎ•ò; ), is the dramatic rise in global interest in South Korean popular culture since the 1990s‚Äîled by K-pop, K-dramas, and films, with keystone successes including \n",
            "\n",
            "==== KPop Demon Hunters ====\n",
            "KPop Demon Hunters is a 2025 American animated musical urban fantasy film directed by Maggie Kang and Chris Appelhans from a screenplay they co-wrote with Danya Jimenez and Hannah McMechan, based on a\n",
            "\n",
            "==== Hybe ====\n",
            "Hybe Co., Ltd. (Korean: ÌïòÏù¥Î∏å; haibeu), commonly known as simply Hybe, is a South Korean multinational entertainment company established in 2005 by Bang Si-hyuk as Big Hit Entertainment Co., Ltd.\n",
            "The co\n",
            "\n",
            "==== BTS ====\n",
            "BTS (Korean: Î∞©ÌÉÑÏÜåÎÖÑÎã®; RR: Bangtan Sonyeondan; lit. Bulletproof Boy Scouts), also known as the Bangtan Boys, is a South Korean boy band formed in 2010. The band consists of Jin, Suga, J-Hope, RM, Jimin, \n",
            "\n",
            "==== 2024 Nobel Prize in Literature ====\n",
            "The 2024 Nobel Prize in Literature was awarded to the South Korean author Han Kang (born 1970) \"for her intense poetic prose that confronts historical traumas and exposes the fragility of human life\".\n",
            "\n",
            "==== Han Kang ====\n",
            "Han Kang (Korean: ÌïúÍ∞ï; born 27 November 1970) is a South Korean writer. From 2007 to 2018, she taught creative writing at the Seoul Institute of the Arts. Han rose to international prominence for her n\n",
            "\n",
            "==== Bong Joon Ho ====\n",
            "Bong Joon Ho (Korean: Î¥âÏ§ÄÌò∏; pronounced [poÀê≈ã t…ïuÀênho]; born September 14, 1969) is a South Korean filmmaker. His work is characterized by emphasis on social and class themes, genre-mixing, dark comedy,\n",
            "\n",
            "==== Pachinko ====\n",
            "Pachinko („Éë„ÉÅ„É≥„Ç≥; pronounced [pat…ïi≈ãko]) is a mechanical game originating in Japan that is used as an arcade game and, much more frequently, for gambling. Pachinko fills a niche in Japanese gambling com\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚úÖ Script A ‚Äî create one TXT file per title\n",
        "\n",
        "- All scripts use Wikipedia API"
      ],
      "metadata": {
        "id": "rp5gGha1olqa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.makedirs(\"wiki_txts\", exist_ok=True)\n",
        "\n",
        "for title in titles:\n",
        "    txt = get_wikipedia_page(title)\n",
        "    if not txt:\n",
        "        print(f\"Skipping: {title}\")\n",
        "        continue\n",
        "\n",
        "    fname = title.replace(\" \", \"_\").replace(\"'\", \"\") + \".txt\"\n",
        "    path = os.path.join(\"wiki_txts\", fname)\n",
        "\n",
        "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(txt)\n",
        "\n",
        "    print(f\"Saved: {path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPACUy0NomoC",
        "outputId": "7eaf35fe-f077-46e6-b1f8-26d992d97d65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: wiki_txts/K-pop.txt\n",
            "Saved: wiki_txts/Korean_Wave.txt\n",
            "Saved: wiki_txts/KPop_Demon_Hunters.txt\n",
            "Saved: wiki_txts/Hybe.txt\n",
            "Saved: wiki_txts/BTS.txt\n",
            "Saved: wiki_txts/2024_Nobel_Prize_in_Literature.txt\n",
            "Saved: wiki_txts/Han_Kang.txt\n",
            "Saved: wiki_txts/Bong_Joon_Ho.txt\n",
            "Saved: wiki_txts/Pachinko.txt\n",
            "Skipping: Minjung Son\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚úÖ Script B ‚Äî Create one TXT file with records separated by @"
      ],
      "metadata": {
        "id": "DbDJlihQpwyM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output = []\n",
        "\n",
        "for title in titles:\n",
        "    txt = get_wikipedia_page(title)\n",
        "    if not txt:\n",
        "        txt = \"\"   # store empty if missing\n",
        "    block = f\"@@@@@\\nTITLE: {title}\\n{txt}\\n\"\n",
        "    output.append(block)\n",
        "\n",
        "final = \"\\n\".join(output)\n",
        "\n",
        "with open(\"wiki_corpus_delimited.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(final)\n",
        "\n",
        "print(\"Saved: wiki_corpus_delimited.txt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQahv4M_p04U",
        "outputId": "202ff9e3-0100-470d-eff9-ec5448fae36f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: wiki_corpus_delimited.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚úÖ Script C ‚Äî Create one CSV with two columns (title + text)\n",
        "\n",
        "#üêπ üêæ üìå **Use this!!!**üìå"
      ],
      "metadata": {
        "id": "DsfmSdsvpSMg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "rows = []\n",
        "\n",
        "for title in titles:\n",
        "    txt = get_wikipedia_page(title)\n",
        "    rows.append([title, txt])\n",
        "\n",
        "with open(\"wiki_corpus.csv\", \"w\", encoding=\"utf-8\", newline=\"\") as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow([\"title\", \"text\"])\n",
        "    writer.writerows(rows)\n",
        "\n",
        "print(\"Saved: wiki_corpus.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hz9fgA47pT7x",
        "outputId": "75fbd3ac-1b87-467c-c69f-e39d85566d8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: wiki_corpus.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color = 'green'>üêπ üêæ **Gutenberg project [by downloading]**"
      ],
      "metadata": {
        "id": "LAeTOcX1wNpa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#üìï **Children's Picture Books**\n",
        "###[**Project Gutenberg**](https://gutenberg.org/)\n",
        "- **Beatrix Potter: Search by 'Beatrix Potter'**\n",
        "    - **The Tale of Peter Rabit**\n",
        "    - **The Tale of Benjamin Bunny**\n",
        "    - **The Tale of Jemima Puddle-Duck**\n",
        "    - **The Tale of Mrs. Tiggy-Winkle**\n",
        "    - **The Tale of Squirrel Nutkin**\n",
        "    - **The Tale of Tom Kitten**\n",
        "\n",
        "- **Leslie Brooke: Search by 'Leslie Brooke'**\n",
        "    - **The Tailor and the Crow**\n",
        "    - **The Golden Goose Book**\n",
        "    - **Jonny Crow's Garden**\n",
        "    - **A Nursery Rhyme Picture Book**"
      ],
      "metadata": {
        "id": "ai_fUazdwuyK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Step 1**\n",
        "\n",
        "- **For each volume, take a look at a published version with the tab, \"READ NOW.\"**\n",
        "- **Download UTF-8 on your machine**\n",
        "- **Open your Î©îÎ™®Ïû• or TextEdit.**\n",
        "- **Save it as plain text.**"
      ],
      "metadata": {
        "id": "Nx5GplLzw1t7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 2**\n",
        "- Make a folder on your Github repository with a new name \"Data_Plain\"\n",
        "- Upload"
      ],
      "metadata": {
        "id": "Ci4EcAxFw6Qh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color = 'red'> üêπüêæ **Final Script to prepare input text for further analysis (e.g., Common Core Words, Wordcloud, Lexical Diversity, etc.)**\n",
        "\n",
        "  - # <font color = 'blue'> üêπüêæ **Important & Useful!**\n",
        "  - ### **This script will be based on plain text for 10 volumes above.**"
      ],
      "metadata": {
        "id": "WKoG5Nt6xINA"
      }
    }
  ]
}