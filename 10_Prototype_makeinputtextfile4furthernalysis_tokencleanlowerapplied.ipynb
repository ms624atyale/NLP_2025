{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOmzcqxbAifTfR4Zos3OI6w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ms624atyale/NLP_PictureBook_2025/blob/main/10_Prototype_makeinputtextfile4furthernalysis_tokencleanlowerapplied.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1Ô∏è‚É£ <font color = 'red'> üêπüêæ **Final Script to prepare input text for further analysis (e.g., Wordcloud, Lexical Diversity, etc.)**\n",
        "\n",
        "  - # <font color = 'blue'> üêπüêæ **Important & Useful!**\n",
        "  - ### **This script is based on plain text for \"Household Stories by the Brothers Grimm\" under the Repository of \"PictureBook_Archive_inProgress\".**"
      ],
      "metadata": {
        "id": "DlRtfSQYdex6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GT0LsgO85fCm"
      },
      "outputs": [],
      "source": [
        "! git clone URL of a Github Repository  #Make copy of the whole repository of a github account."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##<font color = 'red'> üÜò **ALERT**\n",
        "## <font color = 'red'> üÜò **Important & Useful!**\n",
        "\n",
        "## ‚§µÔ∏è In order to avoid setting a new repository being created as a subdirectory of the old one\n",
        "\n",
        "### <font color = 'blue'> <Python code>\n",
        "### <font color = 'blue'> %cd /content  # Moves to the default root directory in Google Colab\n",
        "\n",
        "## ‚§µÔ∏è In order to delete the old directory forcefully\n",
        "\n",
        "### <font color = 'blue'> **‚ñ∂Ô∏è Python code**\n",
        "### <font color = 'gray'> **! rm -rf NameofOldRepository**          \n",
        "\n",
        "### <font color = 'gray'> (e.g., **! rm -rf NLP_PictureBook_2025**)\n",
        "\n",
        "# **If this is not working out, rename the old, existing folder as <Eliminated> and drag the new repository under %content/.**\n"
      ],
      "metadata": {
        "id": "fPmvcdN0KP_0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2Ô∏è‚É£ üêπüêæ **Set up the current directory**"
      ],
      "metadata": {
        "id": "7l39aMcg6QF8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/NameofRepositoryCloned"
      ],
      "metadata": {
        "id": "NyQD9Oxo7Me6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3Ô∏è‚É£ üêπüêæ **Read the txt file**"
      ],
      "metadata": {
        "id": "ugQTa2Md66W5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚ñ∂Ô∏è Step 1: You need to modify this codeline üç©üéÇüçéüçèüç¶\n",
        "file = open(\"/content/RepositoryNameUnderColabFiles/Folder/FileName.txt\", 'rt')\n",
        "\n",
        "txt = file.read()\n",
        "print(txt)\n",
        "file.close() #Using this close()function, you are no longer using your text file of the current workingdirectory with open()function."
      ],
      "metadata": {
        "id": "r_tn-hJp9gje",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4Ô∏è‚É£ üêπüêæ **Install NLTK and Download necessary models**"
      ],
      "metadata": {
        "id": "jt3svU1cp2zm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "id": "gBwuDza2-JwS",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5Ô∏è‚É£ üêπüêæ **Just checking with tokenizing sentences**"
      ],
      "metadata": {
        "id": "pU7HuODPp4H9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "sentence = sent_tokenize(txt)\n",
        "print('Sentence Tokenized: %s' %sentence)"
      ],
      "metadata": {
        "id": "6nya4AxT-2iR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6Ô∏è‚É£ üìçüìç **Apply a series of functions for replacement**"
      ],
      "metadata": {
        "id": "s9pIkCMfI-oc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# ‚ñ∂Ô∏è Step 1: Read file to change path as needed üç©üéÇüçéüçèüç¶\n",
        "with open(\"/content/RepositoryNameUnderColabFiles/Folder/FileName.txt\", 'rt') as fl:\n",
        "    raw_text = fl.read()\n",
        "\n",
        "# ‚ñ∂Ô∏è STEP 2: Clean the text\n",
        "clean_text = (\n",
        "    raw_text\n",
        "    .lower()\n",
        "    .replace(\"\\n\", \" \")\n",
        "    .replace(\"‚Äú\", \"\")\n",
        "    .replace(\"‚Äù\", \"\")\n",
        "    .replace(\"\\\"\", \"\")\n",
        "    .replace(\"_\", \"\")\n",
        "    .replace(\"[illustration]\", \"\")\n",
        "    .replace(\"*\", \"\")\n",
        "    .replace(\".\", \"\")\n",
        "    .replace(\",\", \"\")\n",
        "    .replace(\"(\", \"\")\n",
        "    .replace(\")\", \"\")\n",
        ")\n",
        "\n",
        "# ‚ñ∂Ô∏è STEP 3: Save the cleaned content to a NEW file üç©üéÇüçéüçèüç¶\n",
        "output_path = \"/content/RepositoryNameUnderColabFiles/NewFolder/Title_CLEANED.txt\"\n",
        "with open(output_path, 'w') as cf:\n",
        "    cf.write(clean_text) #Get content named 'clean_text' to the new empty file\n",
        "\n",
        "# ‚ñ∂Ô∏è Optional: Print to verify\n",
        "print(\"‚úÖ Cleaned text saved to:\", output_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9l6dyLoYImhx",
        "outputId": "3661edeb-0c2b-4988-e8b3-5b04f3ade499"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Cleaned text saved to: /content/NLP_PictureBook_2025/Data_PG_Cleaned/1_BenjaminBunny_CLEANED.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7Ô∏è‚É£ üêπüêæ **Just cheking the result file with cleaning applied**\n",
        "- **Sentence Tokenization**\n",
        "- **Tokenizing Words with Regular Tokenizer**\n",
        "- **Get tokenized words put in sequence**"
      ],
      "metadata": {
        "id": "SACJ4rQ5qPo-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "sentence = sent_tokenize(clean_text)\n",
        "print('Sentence Tokenized: %s' %sentence)\n",
        "\n",
        "from nltk.tokenize import RegexpTokenizer #RegexpTokenizer as a class\n",
        "import re\n",
        "\n",
        "tok = RegexpTokenizer(\"[\\w]+\") # Alert: You cannot use RegexpTokenizer() without argument. You need a regexpression formula.\n",
        "\n",
        "tk = tok.tokenize(clean_text)\n",
        "print('Tokenizing Words with RegexpTokenizer: %s' %tk)\n",
        "\n",
        "print(' '.join(tk)) #small characters\n",
        "#alternatively, use the codeline of ' '.join(tkn)"
      ],
      "metadata": {
        "id": "ctwXWSdaKxBf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#‚ö†Ô∏è <font color = 'green'>**This is the end of the Script! You did a good job!** **"
      ],
      "metadata": {
        "id": "DUcWWwfGCGf7"
      }
    }
  ]
}